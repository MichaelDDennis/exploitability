from sacred import Experiment
from sacred.observers import FileStorageObserver
from marl_training import SAVE_DIR as TRAINING_SAVE_DIR
from measure_exploitability import latest_training_sacred_dir
import json

import matplotlib.pyplot as plt
import pandas as pd

from pathlib import Path
import pdb
import numpy as np
import os
import seaborn as sns

SAVE_DIR = "graph_generation"

ex = Experiment("graph_generation")
ex.observers.append(FileStorageObserver(SAVE_DIR))


def plot_reward_traces(reward_traces_df, colors={"A": 'r', "B": 'g'}):
    print(reward_traces_df.index)
    for k, p in reward_traces_df.index:
        if k == 0:
            reward_traces_df.loc[(k, p), :].plot(color=colors[p], label=str(p))
        else:
            reward_traces_df.loc[(k, p), :].plot(color=colors[p], label='_nolegend_')
    plt.legend()


@ex.capture
def get_config_parameter(desired_param, target_run_id, training_dir):
    config_file = os.path.join(training_dir, target_run_id, "rllib", "params.json")
    with open(config_file) as config_fh:
        params = json.load(config_fh)
    return params[desired_param]


def get_feature_from_results(results_file_name, feature):
    with open(results_file_name) as results_file:
        data = []
        for result_line in results_file:
            result = json.loads(result_line)
            for k in feature:
                result = result[k]

            data.append(result)
    return data

@ex.config
def default_config():
    policy_dir = TRAINING_SAVE_DIR
    # TODO do something more sensible here around policy index
    adversary_ind = 0
    victim_ind = 1
    feature_to_graph = ["custom_metrics", "agent2_policy_total_wins_mean"]
    image_dir_loc = 'images'
    target_run_id = latest_training_sacred_dir(policy_dir)
    exploitability_policies = ['baseline']
    exploitability_adversaries = ['total', 'systemic', 'strategic']
    exploitability_dir_dict = None
    colors = {
        'baseline': 'C9',
        'iterative_adversarial_training': 'C6'
    }
    styles = {
        'total': '-',
        'systemic': ':',
        'strategic': '-.'
    }

@ex.command
def episode_length_training_curve(_run, target_run_id, policy_dir, image_dir_loc):


    results_file_name = policy_dir + "/" + str(target_run_id) + "/rllib/result.json"

    feature_to_graph = ["episode_len_mean"]
    data = get_feature_from_results(results_file_name, feature_to_graph)
    plt.plot(data)
    plt.xlabel("Training Steps")
    plt.ylabel("Episode Length Over Training")
    plt.title("Avg Length of Episode Over Training Against Baseline Opponent")

    image_loc = os.path.join(image_dir_loc, "episode_length_curve.png")
    Path(image_dir_loc).mkdir(parents=True, exist_ok=True)
    plt.savefig(image_loc)
    ex.add_artifact(image_loc)


def get_latest_sacred_dir_with_policy_and_adversary(policy_dir, policy_type, adversary_type):
    max_val = np.inf
    while True:
        latest_dir = latest_training_sacred_dir(policy_dir, max_val=max_val)
        if latest_dir == "-1":
            break
        with open(os.path.join(policy_dir, latest_dir, 'config.json')) as fp:
            config = json.load(fp)
            if config.get("adversary_type_key") == adversary_type and config.get("victim_policy_key") == policy_type:
                print(f"Found directory for policy={policy_type}, adversary_type={adversary_type}: {latest_dir}")
                return latest_dir
            else:
                max_val = int(latest_dir)
        if max_val <= 0:
            break
    raise FileNotFoundError(f"No sacred run found with policy {policy_type} and adversary type {adversary_type}")

def get_adversary_data(results_file_name, feature):
    adversary_list = []
    with open(results_file_name) as results_file:
        adversary = None
        for result_line in results_file:
            result = json.loads(result_line)
            if int(result['training_iteration']) == 1:
                if adversary is not None:
                    adversary_list.append(adversary)
                adversary = []
            for k in feature:
                result = result[k]
            adversary.append(result)
        adversary_list.append(adversary)
    return np.array(adversary_list)


def get_param_val(policy_dir, run_id, param):
    with open(os.path.join(policy_dir, run_id, 'config.json')) as fp:
        config = json.load(fp)
        return config.get(param)

@ex.capture
def get_exploitability_data(policy_dir, exploitability_dir_dict, exploitability_policies, exploitability_adversaries):
    if exploitability_dir_dict is None:
        exploitability_dir_dict = {}
        for policy in exploitability_policies:
            for adversary in exploitability_adversaries:
                sacred_dir = get_latest_sacred_dir_with_policy_and_adversary(policy_dir, policy, adversary)
                exploitability_dir_dict[f"{policy}_{adversary}"] = sacred_dir

    exploitability_data = {}
    for experiment_name, run_id in exploitability_dir_dict.items():
        results_file_name = policy_dir + "/" + str(run_id) + "/rllib/result.json"
        adv_index = get_param_val(policy_dir, run_id, "adv_index")
        # TODO make this more general over features, this is a bit hard to do in a way that still allows dynamic adv_index
        adversary_data = get_adversary_data(results_file_name, ['custom_metrics', f'agent{adv_index+1}_policy_utility_mean'])
        exploitability_data[experiment_name] = adversary_data
    return exploitability_data

@ex.command
def exploitability_curves(_run, image_dir_loc, colors, styles):


    exploitability_data = get_exploitability_data()
    for experiment_name, data_array in exploitability_data.items():
        adversary_average = np.mean(data_array, axis=0)
        adversary_stdev = np.std(data_array, axis=0)
        policy, adversary = experiment_name.split("_")
        plt.plot(adversary_average, label=experiment_name, color=colors[policy], linestyle=styles[adversary])

    plt.legend()
    plt.title("Utility Over Adversary Training")
    image_loc = os.path.join(image_dir_loc, "exploitability_curves.png")

    Path(image_dir_loc).mkdir(parents=True, exist_ok=True)

    plt.savefig(image_loc)
    ex.add_artifact(image_loc)



@ex.command
def exploitability_bar_chart(image_dir_loc):
    exploitability_data = get_exploitability_data()
    final_exploitability_values = []
    for experiment_name, data_array in exploitability_data.items():
        policy, adversary = experiment_name.split('_')
        final_step = data_array[:,-1]
        for val in final_step:
            final_exploitability_values.append({'policy': policy, 'adversary': adversary, 'utility': val})

    final_values_df = pd.DataFrame(final_exploitability_values)
    sns.barplot(data=final_values_df, x="policy", y="utility", hue="adversary")
    image_loc = os.path.join(image_dir_loc, "exploitability_bar_plot.png")

    Path(image_dir_loc).mkdir(parents=True, exist_ok=True)
    plt.savefig(image_loc)
    ex.add_artifact(image_loc)


def plot_traces(trace_df):
    trace_df.plot(color='r', label="rest")
    plt.legend()

@ex.automain
def my_main(_run, target_run_id, training_dir, feature_to_graph, image_dir_loc):
    results_file_name = training_dir + "/" + str(target_run_id) + "/rllib/result.json"

    with open(results_file_name) as results_file:
        data = []
        for result_line in results_file:
            result = json.loads(result_line)
            for k in feature_to_graph:
                result = result[k]

            data.append(result)

        data_dic = {"test": data}
        print(data)

    rewards_df = pd.DataFrame(data_dic)

    plot_traces(rewards_df)
    image_loc = image_dir_loc + "/" + str(_run._id) + ".png"

    Path(image_dir_loc).mkdir(parents=True, exist_ok=True)

    plt.savefig(image_loc)
    ex.add_artifact(image_loc)
