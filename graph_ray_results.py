from sacred import Experiment
from sacred.observers import FileStorageObserver
from marl_training import SAVE_DIR as TRAINING_SAVE_DIR
from measure_exploitability import latest_training_sacred_dir
import json

import matplotlib.pyplot as plt
import pandas as pd

from pathlib import Path
import pdb
import numpy as np
import os

SAVE_DIR = "graph_generation"

ex = Experiment("graph_generation")
ex.observers.append(FileStorageObserver(SAVE_DIR))


def plot_reward_traces(reward_traces_df, colors={"A": 'r', "B": 'g'}):
    print(reward_traces_df.index)
    for k, p in reward_traces_df.index:
        if k == 0:
            reward_traces_df.loc[(k, p), :].plot(color=colors[p], label=str(p))
        else:
            reward_traces_df.loc[(k, p), :].plot(color=colors[p], label='_nolegend_')
    plt.legend()


@ex.capture
def get_config_parameter(desired_param, target_run_id, training_dir):
    config_file = os.path.join(training_dir, target_run_id, "rllib", "params.json")
    with open(config_file) as config_fh:
        params = json.load(config_fh)
    return params[desired_param]


def get_feature_from_results(results_file_name, feature):
    with open(results_file_name) as results_file:
        data = []
        for result_line in results_file:
            result = json.loads(result_line)
            for k in feature:
                result = result[k]

            data.append(result)
    return data

@ex.config
def default_config():
    training_dir = TRAINING_SAVE_DIR
    # TODO do something more sensible here around policy index
    adversary_ind = 0
    victim_ind = 1
    image_dir_loc = 'images'
    target_run_id = latest_training_sacred_dir(training_dir)
    exploitability_policies = ['baseline']
    exploitability_adversaries = ['total', 'systematic', 'strategic']

@ex.command
def episode_length_training_curve(_run, target_run_id, training_dir, image_dir_loc):

    results_file_name = training_dir + "/" + str(target_run_id) + "/rllib/result.json"

    feature_to_graph = ["episode_len_mean"]
    data = get_feature_from_results(results_file_name, feature_to_graph)
    plt.plot(data)
    plt.xlabel("Training Steps")
    plt.ylabel("Episode Length Over Training")
    plt.title("Avg Length of Episode Over Training Against Baseline Opponent")

    image_loc = image_dir_loc + "/" + str(_run._id) + ".png"
    Path(image_dir_loc).mkdir(parents=True, exist_ok=True)

    plt.savefig(image_loc)
    ex.add_artifact(image_loc)


def get_latest_sacred_dir_with_policy_and_adversary(policy_dir, policy_type, adversary_type):
    max_val = np.inf
    while max_val :
        latest_dir = latest_training_sacred_dir(policy_dir, max_val=max_val)
        with open(os.path.join(latest_dir, 'config.json')) as fp:
            config = json.load(fp)
            if config["adversary_type_key"] == adversary_type and config["victim_policy_key"] == policy_type:
                return latest_dir
            else:
                max_val = int(latest_dir)




@ex.command
def exploitability_curves()


@ex.automain
def my_main(_run, target_run_id, training_dir, feature_to_graph, image_dir_loc):
    results_file_name = training_dir + "/" + str(target_run_id) + "/rllib/result.json"

    with open(results_file_name) as results_file:
        data = []
        for result_line in results_file:
            result = json.loads(result_line)
            for k in feature_to_graph:
                result = result[k]

            data.append(result)

        data_dic = {"test": data}
        print(data)

    rewards_df = pd.DataFrame(data_dic)
    pdb.set_trace()
    plot_traces(rewards_df)
    image_loc = image_dir_loc + "/" + str(_run._id) + ".png"
    Path(image_dir_loc).mkdir(parents=True, exist_ok=True)

    plt.savefig(image_loc)
    ex.add_artifact(image_loc)
