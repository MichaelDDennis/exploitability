from ray.rllib.agents.pg.pg import PGTrainer
from ray.rllib.agents.pg.pg_policy import PGTFPolicy
from ray.rllib.agents.ppo.ppo import PPOTrainer
from ray.rllib.agents.ppo.ppo_policy import PPOTFPolicy


def policy_mapping_fn(agent_id):
    return "agent"+str(agent_id % 2+1)+"_policy"


def get_ppo_train(name, pols, env):
    return PPOTrainer(
        env=env,
        config={
            "multiagent": {
                "policies": pols,
                "policy_mapping_fn": policy_mapping_fn,
                "policies_to_train": [name],
            },
            # disable filters, otherwise we would need to synchronize those
            # as well to the DQN agent
            "observation_filter": "NoFilter",
        })


def get_pg_train(name, pols, env):
    return PGTrainer(
        env=env,
        config={
            "multiagent": {
                "policies": pols,
                "policy_mapping_fn": policy_mapping_fn,
                "policies_to_train": [name],
            },
            # disable filters, otherwise we would need to synchronize those
            # as well to the DQN agent
            "observation_filter": "NoFilter",
        })


def get_ppo_pol(obs_space, act_space):
    return PPOTFPolicy, obs_space, act_space, {}


def get_pg_pol(obs_space, act_space):
    return PGTFPolicy, obs_space, act_space, {}


ALG_POL_MAP = {"pg": get_pg_pol, "ppo": get_ppo_pol}
ALG_TRAIN_MAP = {"pg": get_pg_train, "ppo": get_ppo_train}


def get_algs(algs, obs_space, act_space, env):
    pols = {policy_mapping_fn(i): ALG_POL_MAP[alg](obs_space, act_space) for i, alg in enumerate(algs)}

    return [ALG_TRAIN_MAP[alg](policy_mapping_fn(i), pols, env) for i, alg in enumerate(algs)], pols


def get_new_train(alg, env, pols, index):
    return ALG_TRAIN_MAP[alg](policy_mapping_fn(index), pols, env)
