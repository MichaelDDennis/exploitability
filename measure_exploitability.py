from sacred import Experiment
from sacred.observers import FileStorageObserver

from tqdm import tqdm

import ray
from ray.tune.logger import pretty_print

from env_utils import get_env

from alg_utils import get_algs, get_new_train

from marl_training import sync_trainers

from sacred import SETTINGS
SETTINGS['CAPTURE_MODE'] = 'sys'

SAVE_DIR = "my_runs"

exploitability_ex = Experiment("measure_exploitability")
exploitability_ex.observers.append(FileStorageObserver(SAVE_DIR))


@exploitability_ex.config
def my_config():
    agent1_alg = "pg"
    agent2_alg = "pg"
    env = "tictactoe-v0"
    trainning_iters = 1000
    samples = 100
    dim = 2


VIC_INDEX = 0
ADV_INDEX = 1


@exploitability_ex.automain
def my_main(_run, prev_run, agent1_alg, dim, agent2_alg, env, samples, trainning_iters):
    ray.init()
    obs_space, act_space, env = get_env(env, dim)

    trainers, pols = get_algs([agent1_alg, agent2_alg], obs_space, act_space, env)

    #TODO fix this name, the indexing is saved weird
    trainers[VIC_INDEX].restore(SAVE_DIR+"/"+str(prev_run)+"/checkpoints/checkpoint_1/checkpoint-1")

    for t in range(samples):
        adv = get_new_train(agent2_alg, env, pols, 1)
        trainers[ADV_INDEX] = adv
        sync_trainers(trainers)
        print("before")
        print(pretty_print(adv.train()))
        for _ in tqdm(range(trainning_iters)):
            sync_trainers(trainers)

            adv.train()
        print("after")
        print(pretty_print(adv.train()))

    sync_trainers(trainers)

    trainers[1].save(SAVE_DIR+"/"+str(_run._id)+"/checkpoints/")
