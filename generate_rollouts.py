from sacred import Experiment
from sacred.observers import FileStorageObserver

from tictactoe_wrapper import MultiAgentTicTacToe
from marl_training import policy_mapping_fn, sync_trainers, simulate_rollouts_tictactoe
from env_utils import get_env
import ray
from alg_utils import get_algs
from measure_exploitability import _get_checkpoint_from_run



ex = Experiment("simulate_rollouts")

@ex.config
def my_config():
    agent1_alg = "pg"
    agent2_alg = "pg_hierarchical_1by256"
    env = "tictactoe-v0"
    dim = 10
    training_iters = 200
    simulate_trained_pols = True
    silent = True
    gamma = 0.95
    checkpoint_freq = 50

@ex.automain
def my_main(_run, agent1_alg, agent2_alg, dim, env, simulate_trained_pols, target, dir_loc):
    ray.init()
    obs_space, act_space, env_name = get_env(env, dim)

    trainers, pols = get_algs([agent1_alg, agent2_alg], obs_space, act_space, dim, env_name, "~/raydir/")

    trainers[0].restore(_get_checkpoint_from_run(target, 0, dir_loc))
    trainers[1].restore(_get_checkpoint_from_run(target, 1, dir_loc))

    sync_trainers(trainers)

    if simulate_trained_pols:
        simulate_rollouts_tictactoe(trainers, dim)
